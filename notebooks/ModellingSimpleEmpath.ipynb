{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3be6938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/harshapk/Projects/CSS_Project\n"
     ]
    }
   ],
   "source": [
    "%cd ../\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0ba994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./data/data_processed/lies_data_cleaned.pkl\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "191df178",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[dataset[\"lang\"] == \"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6eb2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[[\"tweet_text\", \"retweets\", \"likes\", \"user_description\", \"user_following\",\n",
    "\"user_followers\", \"user_verified\", \"user_total_tweets\", \"user_total_likes\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5abe2f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['na', 'neg', 'pos'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cfb7177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from css_proj.models.bertembed import get_sentence_embed\n",
    "import transformers as ppb\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dc8d5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2891/2891 [03:35<00:00, 13.42it/s]\n"
     ]
    }
   ],
   "source": [
    "from css_proj.models.clean_tweet import process_text\n",
    "all_tw_text = dataset[\"tweet_text\"].tolist()\n",
    "all_tw_text_embed = [get_sentence_embed([process_text(text)], model, tokenizer).numpy() \n",
    "                     for text in tqdm(all_tw_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3abacd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tw_text_embed = np.array(all_tw_text_embed)\n",
    "all_tw_text_embed = all_tw_text_embed.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fa893c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2891/2891 [03:39<00:00, 13.14it/s]\n"
     ]
    }
   ],
   "source": [
    "all_tw_desc = dataset[\"user_description\"].tolist()\n",
    "all_tw_desc_embed = [get_sentence_embed([process_text(text)], model, tokenizer).numpy() for text in tqdm(all_tw_desc)]\n",
    "all_tw_desc_embed = np.array(all_tw_desc_embed).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b5303a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/data_processed/covid_lies_embed.pkl\", \"wb\") as f:\n",
    "    pickle.dump([all_tw_text_embed, all_tw_desc_embed], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c42e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/data_processed/covid_lies_embed.pkl\", \"rb\") as f:\n",
    "    all_tw_text_embed, all_tw_desc_embed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf08e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"num_label\"] = dataset[\"label\"].apply(lambda x: 0 if x == \"na\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43d5c406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"doctors\", \"doctor\", \"treatment\", \"patient\", \"illness\", \"hospital\", \"health\", \"surgery\", \"condition\", \"medication\", \"patients\", \"disease\", \"treatments\", \"sickness\", \"labour\", \"labor\", \"chemo\", \"operation\", \"recovery\", \"surgeon\", \"Doctors\", \"psychiatrist\", \"medicine\", \"clinic\", \"pregnancy\", \"therapy\", \"cancer\", \"intensive_care\", \"nurse\", \"symptoms\", \"ward\", \"diagnosis\", \"therapist\", \"trauma\", \"midwife\", \"surgeons\", \"physician\", \"blood_tests\", \"injuries\", \"critical_condition\", \"infection\", \"psychologist\", \"procedure\", \"chemotherapy\", \"tumor\", \"pneumonia\", \"local_hospital\", \"healer\", \"emergency_room\", \"injury\", \"injection\", \"coma\", \"test_results\", \"donor\", \"serious_injuries\", \"medically\", \"prescribed\", \"emergency_surgery\", \"autopsy\", \"nurses\", \"side_effects\", \"Alzheimer\", \"medications\", \"healers\", \"cure\", \"minor_injuries\", \"flu\", \"meds\", \"discharged\", \"suffering\", \"scans\", \"pack_doctor\", \"tests\", \"cured\", \"complications\", \"life_support\", \"blood_transfusion\", \"ICU\", \"blood_test\", \"head_injury\", \"scan\", \"memory_loss\", \"full_recovery\", \"serum\", \"blood_sample\", \"surgeries\", \"seizures\", \"x-rays\", \"results\", \"rehab\", \"examination\", \"pain_medication\", \"antibiotics\", \"brain_damage\", \"prescription\", \"bed_rest\", \"therapy_sessions\", \"depression\", \"state\", \"radiation\"]\n"
     ]
    }
   ],
   "source": [
    "from empath import Empath\n",
    "lexicon = Empath()\n",
    "lexicon.create_category(\"medical\", [\"doctor\", \"physician\", \"hospital\", \"health\", \"disease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd3f8c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"remarkable\", \"admirable\", \"questionable\", \"exceptional\", \"astounding\", \"certainly\", \"yet\", \"Though\", \"desirable\", \"extraordinary\", \"wise\", \"although\", \"practical\", \"simplicity\", \"gifted\", \"pleasing\", \"humble\", \"adequate\", \"honorable\", \"outstanding\", \"respectable\", \"rarity\", \"bearing\", \"quality\", \"enlightened\", \"Yet\", \"potential\", \"agreeable\", \"certain\", \"appeal\", \"sensible\", \"lacking\", \"Yet\", \"appreciative\", \"endowed\", \"satisfactory\", \"valued\", \"truly\", \"devoted\", \"confident\", \"refined\", \"perceived\", \"formidable\", \"own_right\", \"successful\", \"knowledgeable\", \"astonishing\", \"intelligence\", \"Although\", \"ambition\", \"outrageous\", \"powerful\", \"thorough\", \"appealing\", \"promising\", \"costly\", \"ideal\", \"worthy\", \"wicked\", \"wondrous\", \"undoubtedly\", \"noble\", \"boast\", \"however\", \"enchanting\", \"superficial\", \"though\", \"miraculous\", \"spiritual\", \"potential\", \"primitive\", \"grateful\", \"though\", \"flawed\", \"superior\", \"splendid\", \"unlike\", \"inadequate\", \"fascinating\", \"individual\", \"Moreover\", \"reliable\", \"greatest\", \"astonishing\", \"aspects\", \"brilliant\", \"logical\", \"unfortunate\", \"rewarding\", \"desired\", \"lacks\", \"resilient\", \"nature\", \"elusive\", \"magnificent\", \"partial\", \"despised\", \"seldom\", \"spectacular\"]\n",
      "[\"Yet\", \"Yet\", \"yet\", \"intolerable\", \"nuisance\", \"sickening\", \"fear\", \"Though\", \"surely\", \"wretched\", \"though\", \"terrifying\", \"shameful\", \"useless\", \"prone\", \"sickened\", \"unpleasant\", \"rash\", \"failure\", \"cruelty\", \"however\", \"rational\", \"although\", \"provoked\", \"certain\", \"brutality\", \"though\", \"bitter\", \"frightening\", \"literal\", \"questionable\", \"vulnerable\", \"savage\", \"turmoil\", \"carelessness\", \"angry\", \"feared\", \"ignorance\", \"corrupted\", \"cruel\", \"extreme\", \"troubled\", \"unavoidable\", \"inhuman\", \"dangerous\", \"extreme\", \"weak\", \"perceived\", \"foolish\", \"vicious\", \"affecting\", \"undoubtedly\", \"painful\", \"impossible\", \"somehow\", \"meaningless\", \"careless\", \"fearful\", \"desperate\", \"violent\", \"angered\", \"immune\", \"brutal\", \"infuriating\", \"revolted\", \"appeal\", \"unnatural\", \"devastating\", \"lethal\", \"possessed\", \"disliking\", \"Though\", \"afraid\", \"downfall\", \"misfortune\", \"dying\", \"certainly\", \"ruthless\", \"nonexistent\", \"However\", \"cowardice\", \"terrifying\", \"affected\", \"menace\", \"threat\", \"harmful\", \"effected\", \"knowing\", \"tainted\", \"unreasonable\", \"enough\", \"paranoia\"]\n"
     ]
    }
   ],
   "source": [
    "def get_words_from_txt(path):\n",
    "    return pd.read_table(path, header=None).to_numpy().squeeze()\n",
    "positive_words = get_words_from_txt(\"data/data_raw/positive-words.txt\")\n",
    "negative_words = get_words_from_txt(\"data/data_raw/negative-words.txt\")\n",
    "lexicon.create_category(\"positive_sent\", list(positive_words))\n",
    "lexicon.create_category(\"negative_sent\", list(negative_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5efccce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"user_medical\"] = dataset[\"user_description\"].apply(\n",
    "    lambda x: lexicon.analyze(x, categories=[\"medical\"])[\"medical\"])\n",
    "dataset[\"positive_sent\"] = dataset[\"tweet_text\"].apply(\n",
    "    lambda x: lexicon.analyze(x, categories=[\"positive_sent\", \"negative_sent\"])[\"positive_sent\"])\n",
    "dataset[\"negative_sent\"] = dataset[\"tweet_text\"].apply(\n",
    "    lambda x: lexicon.analyze(x, categories=[\"positive_sent\", \"negative_sent\"])[\"negative_sent\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe147498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>retweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_following</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_total_tweets</th>\n",
       "      <th>user_total_likes</th>\n",
       "      <th>label</th>\n",
       "      <th>num_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Getting coronavirus and then coughing on peopl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Tankie</td>\n",
       "      <td>233</td>\n",
       "      <td>304</td>\n",
       "      <td>False</td>\n",
       "      <td>1873</td>\n",
       "      <td>33404</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>“Most people (not elderly, no underlying healt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gran</td>\n",
       "      <td>2038</td>\n",
       "      <td>2826</td>\n",
       "      <td>False</td>\n",
       "      <td>198290</td>\n",
       "      <td>80072</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15-20% of people with COVID-19 may require hos...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Wife, Mom, Grandmother - Retired Paramedic/FF</td>\n",
       "      <td>247</td>\n",
       "      <td>220</td>\n",
       "      <td>False</td>\n",
       "      <td>7913</td>\n",
       "      <td>40570</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A sheriff's office tried to get meth off the s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WBAL NewsRadio 1090 and FM 101.5, the home of ...</td>\n",
       "      <td>4075</td>\n",
       "      <td>72865</td>\n",
       "      <td>True</td>\n",
       "      <td>125399</td>\n",
       "      <td>917</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>In China’s War on the Coronavirus, a Community...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Single, \"God Fearing Man\"! The Lord, Loves Us ...</td>\n",
       "      <td>1632</td>\n",
       "      <td>138</td>\n",
       "      <td>False</td>\n",
       "      <td>56083</td>\n",
       "      <td>16498</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6583</th>\n",
       "      <td>Scientists say a cutting-edge but untested new...</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>Australia's leading news source. Independent. ...</td>\n",
       "      <td>743</td>\n",
       "      <td>877029</td>\n",
       "      <td>True</td>\n",
       "      <td>230887</td>\n",
       "      <td>592</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6586</th>\n",
       "      <td>One Spokane County resident is displaying symp...</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>The Spokesman-Review is the Spokane region's o...</td>\n",
       "      <td>1482</td>\n",
       "      <td>61932</td>\n",
       "      <td>False</td>\n",
       "      <td>70326</td>\n",
       "      <td>1545</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6587</th>\n",
       "      <td>@ALBeforeAfter Orion is my favorite constellat...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18+ Adults ONLY!!! We are a couple in our 30's...</td>\n",
       "      <td>2484</td>\n",
       "      <td>67728</td>\n",
       "      <td>False</td>\n",
       "      <td>13331</td>\n",
       "      <td>75500</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6589</th>\n",
       "      <td>@LindaJones_NYC China is dirty.\\nWhen people c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Livin' the dream....\\nWe The People #MovedOnTr...</td>\n",
       "      <td>5001</td>\n",
       "      <td>2616</td>\n",
       "      <td>False</td>\n",
       "      <td>58217</td>\n",
       "      <td>74884</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6590</th>\n",
       "      <td>Watching Nostradamus. \\nNostradamus has  predi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Retired computer professional, \\nscience ficti...</td>\n",
       "      <td>217</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>18643</td>\n",
       "      <td>1317</td>\n",
       "      <td>na</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2715 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             tweet_text  retweets  likes  \\\n",
       "1     Getting coronavirus and then coughing on peopl...         1      0   \n",
       "9     “Most people (not elderly, no underlying healt...         0      0   \n",
       "13    15-20% of people with COVID-19 may require hos...         0      0   \n",
       "15    A sheriff's office tried to get meth off the s...         0      0   \n",
       "16    In China’s War on the Coronavirus, a Community...         0      0   \n",
       "...                                                 ...       ...    ...   \n",
       "6583  Scientists say a cutting-edge but untested new...         9     18   \n",
       "6586  One Spokane County resident is displaying symp...        13      9   \n",
       "6587  @ALBeforeAfter Orion is my favorite constellat...         0      5   \n",
       "6589  @LindaJones_NYC China is dirty.\\nWhen people c...         0      0   \n",
       "6590  Watching Nostradamus. \\nNostradamus has  predi...         0      1   \n",
       "\n",
       "                                       user_description  user_following  \\\n",
       "1                                                Tankie             233   \n",
       "9                                                  gran            2038   \n",
       "13        Wife, Mom, Grandmother - Retired Paramedic/FF             247   \n",
       "15    WBAL NewsRadio 1090 and FM 101.5, the home of ...            4075   \n",
       "16    Single, \"God Fearing Man\"! The Lord, Loves Us ...            1632   \n",
       "...                                                 ...             ...   \n",
       "6583  Australia's leading news source. Independent. ...             743   \n",
       "6586  The Spokesman-Review is the Spokane region's o...            1482   \n",
       "6587  18+ Adults ONLY!!! We are a couple in our 30's...            2484   \n",
       "6589  Livin' the dream....\\nWe The People #MovedOnTr...            5001   \n",
       "6590  Retired computer professional, \\nscience ficti...             217   \n",
       "\n",
       "      user_followers user_verified  user_total_tweets  user_total_likes label  \\\n",
       "1                304         False               1873             33404    na   \n",
       "9               2826         False             198290             80072    na   \n",
       "13               220         False               7913             40570    na   \n",
       "15             72865          True             125399               917    na   \n",
       "16               138         False              56083             16498    na   \n",
       "...              ...           ...                ...               ...   ...   \n",
       "6583          877029          True             230887               592    na   \n",
       "6586           61932         False              70326              1545    na   \n",
       "6587           67728         False              13331             75500    na   \n",
       "6589            2616         False              58217             74884    na   \n",
       "6590             200         False              18643              1317    na   \n",
       "\n",
       "      num_label  \n",
       "1             0  \n",
       "9             0  \n",
       "13            0  \n",
       "15            0  \n",
       "16            0  \n",
       "...         ...  \n",
       "6583          0  \n",
       "6586          0  \n",
       "6587          0  \n",
       "6589          0  \n",
       "6590          0  \n",
       "\n",
       "[2715 rows x 11 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset['label']=='na']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "099f0196",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_array = dataset[[\"retweets\", \"likes\", \"user_following\",\n",
    "\"user_followers\", \"user_verified\", \"user_total_tweets\", \"user_total_likes\", \"user_medical\",\n",
    "                         \"positive_sent\", \"negative_sent\", \"num_label\"]]\n",
    "dataset_array = np.array(dataset_array).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ea70dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_array = np.hstack([all_tw_desc_embed, all_tw_text_embed, dataset_array])\n",
    "dataset_x = dataset_array[:, :-1]\n",
    "dataset_y = dataset_array[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70520a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(dataset_x, dataset_y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af06bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e83ebb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harshapk/Projects/CSS_Project/.envs/css_proj/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f529191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.909248055315471\n",
      "[[1043   33]\n",
      " [  72    9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.95      1076\n",
      "         1.0       0.21      0.11      0.15        81\n",
      "\n",
      "    accuracy                           0.91      1157\n",
      "   macro avg       0.57      0.54      0.55      1157\n",
      "weighted avg       0.88      0.91      0.90      1157\n",
      "\n",
      "0.14634146341463417\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "pred_y = logreg.predict(test_x)\n",
    "print(accuracy_score(test_y, pred_y))\n",
    "print(confusion_matrix(test_y, pred_y))\n",
    "print(classification_report(test_y, pred_y))\n",
    "print(f1_score(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ece041dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d946ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9204840103716508\n",
      "[[1061   15]\n",
      " [  77    4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.99      0.96      1076\n",
      "         1.0       0.21      0.05      0.08        81\n",
      "\n",
      "    accuracy                           0.92      1157\n",
      "   macro avg       0.57      0.52      0.52      1157\n",
      "weighted avg       0.88      0.92      0.90      1157\n",
      "\n",
      "0.08\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "pred_y = rfc.predict(test_x)\n",
    "print(accuracy_score(test_y, pred_y))\n",
    "print(confusion_matrix(test_y, pred_y))\n",
    "print(classification_report(test_y, pred_y))\n",
    "print(f1_score(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25396c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel=\"linear\", random_state=42)\n",
    "svc.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c93612c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8962834917891098\n",
      "[[1020   56]\n",
      " [  64   17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.95      0.94      1076\n",
      "         1.0       0.23      0.21      0.22        81\n",
      "\n",
      "    accuracy                           0.90      1157\n",
      "   macro avg       0.59      0.58      0.58      1157\n",
      "weighted avg       0.89      0.90      0.89      1157\n",
      "\n",
      "0.22077922077922077\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "pred_y = svc.predict(test_x)\n",
    "print(accuracy_score(test_y, pred_y))\n",
    "print(confusion_matrix(test_y, pred_y))\n",
    "print(classification_report(test_y, pred_y))\n",
    "print(f1_score(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a195e22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM with RBF kernel\n",
    "svc_rbf = SVC(kernel=\"rbf\", random_state=42)\n",
    "svc_rbf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d777b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9299913569576491\n",
      "[[1076    0]\n",
      " [  81    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      1.00      0.96      1076\n",
      "         1.0       0.00      0.00      0.00        81\n",
      "\n",
      "    accuracy                           0.93      1157\n",
      "   macro avg       0.46      0.50      0.48      1157\n",
      "weighted avg       0.86      0.93      0.90      1157\n",
      "\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harshapk/Projects/CSS_Project/.envs/css_proj/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/harshapk/Projects/CSS_Project/.envs/css_proj/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/harshapk/Projects/CSS_Project/.envs/css_proj/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "pred_y = svc_rbf.predict(test_x)\n",
    "print(accuracy_score(test_y, pred_y))\n",
    "print(confusion_matrix(test_y, pred_y))\n",
    "print(classification_report(test_y, pred_y))\n",
    "print(f1_score(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5410290a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(100, 100, 100), random_state=42)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(random_state=42, hidden_layer_sizes=(100, 100, 100))\n",
    "mlp.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e162c4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9127052722558341\n",
      "[[1047   29]\n",
      " [  72    9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.95      1076\n",
      "         1.0       0.24      0.11      0.15        81\n",
      "\n",
      "    accuracy                           0.91      1157\n",
      "   macro avg       0.59      0.54      0.55      1157\n",
      "weighted avg       0.89      0.91      0.90      1157\n",
      "\n",
      "0.15126050420168066\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "pred_y = mlp.predict(test_x)\n",
    "print(accuracy_score(test_y, pred_y))\n",
    "print(confusion_matrix(test_y, pred_y))\n",
    "print(classification_report(test_y, pred_y))\n",
    "print(f1_score(test_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf24b7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
